<DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>[ML]AwesomeXGBoost-炼丹秘籍</title>
    <meta name="viewport" content="width=device-width">
    <meta name="description" content="致力于算法，数据和工程的全链路打通">
    <link rel="canonical" href="http://localhost:4000/2017/10/19/xgboost-tuning/">
    <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="ZHPMATRIX blog posts" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">
    <!-- Personal visit times -->
    <script>
	var _hmt = _hmt || [];
	(function() {
  		var hm = document.createElement("script");
  		hm.src = "//hm.baidu.com/hm.js?39e5930446e371d66d738fef008c3ce2";
  		var s = document.getElementsByTagName("script")[0]; 
  		s.parentNode.insertBefore(hm, s);
	})();
	</script>
 </head>


    <body>
    <header class="site-header">

  <div class="wrap">

    <div style="float:floate; margin-top:10px; margin-right:50px;"></div>
    <a class="site-title" href="/">ZHPMATRIX blog</a>
    <a class="site-title" href="/project.html">项目</a>
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
</a>
      <div class="trigger">
        
          <a class="page-link" href="/about/">关于我</a>
        
          
        
          
        
      </div>
    </nav>
  </div>
  <!-- Personal visit times -->
  <script>
  var _hmt = _hmt || [];
  (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?39e5930446e371d66d738fef008c3ce2";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
  })();
  </script>
  <style>
	body{background-color:#84bf97}
  </style>
 </header>


    <!--<div class="page-content" style="background-color:#F8F8FF;">-->
    <div class="page-content">
      <div class="wrap">
      <div class="post">

  <header class="post-header">
    <h1>[ML]AwesomeXGBoost-炼丹秘籍</h1>
    <p class="meta">Oct 19, 2017</p>
  </header>

  <article class="post-content">
  <p>前言：这篇博客是从jupyter notebook文档直接转换为markdown得到，相关资源如下。</p>

<p><a href="https://nbviewer.jupyter.org/github/zhpmatrix/awesome-xgb/blob/master/AwesomeXGBoost.ipynb">本篇博客的在线notebook</a></p>

<p><a href="https://github.com/zhpmatrix/awesome-xgb">Github代码地址</a></p>

<h2 id="xgboost基本参数调节">XGBoost基本参数调节</h2>

<p>参考：</p>

<p><a href="https://cambridgespark.com/content/tutorials/hyperparameter-tuning-in-xgboost/index.html">Hyperparameter tuning in XGBoost</a></p>

<p>这篇博客是native XGBoost API</p>

<p><a href="https://cambridgespark.com/content/tutorials/getting-started-with-xgboost/index.html">Get started with XGBoost</a></p>

<p>这篇博客是sklearn API</p>

<p><a href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/">Complete Guide to Parameter Tuning in XGBoost(with codes in Python)</a></p>

<p>这篇博客是sklearn API</p>

<h2 id="使用xgboost自定义目标函数和评估函数">使用XGBoost自定义目标函数和评估函数</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="n">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="c1">###
# advanced: customized loss function
#
</span><span class="k">print</span> <span class="p">(</span><span class="s">'start running example to used customized objective function'</span><span class="p">)</span>

<span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="s">'data/agaricus.txt.train'</span><span class="p">)</span>
<span class="n">dtest</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="s">'data/agaricus.txt.test'</span><span class="p">)</span>

<span class="c1"># note: for customized objective function, we leave objective as default
# note: what we are getting is margin value in prediction
# you must know what you are doing
</span><span class="n">param</span> <span class="o">=</span> <span class="p">{</span><span class="s">'max_depth'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s">'eta'</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">}</span>
<span class="n">watchlist</span> <span class="o">=</span> <span class="p">[(</span><span class="n">dtest</span><span class="p">,</span> <span class="s">'eval'</span><span class="p">),</span> <span class="p">(</span><span class="n">dtrain</span><span class="p">,</span> <span class="s">'train'</span><span class="p">)]</span>
<span class="n">num_boost_round</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1"># user define objective function, given prediction, return gradient and second order gradient
# this is log likelihood loss
</span><span class="k">def</span> <span class="nf">logregobj</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">dtrain</span><span class="p">):</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">dtrain</span><span class="p">.</span><span class="n">get_label</span><span class="p">()</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">preds</span><span class="p">))</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">preds</span> <span class="o">-</span> <span class="n">labels</span>
    <span class="n">hess</span> <span class="o">=</span> <span class="n">preds</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">preds</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">grad</span><span class="p">,</span> <span class="n">hess</span>

<span class="c1"># user defined evaluation function, return a pair metric_name, result
# NOTE: when you do customized loss function, the default prediction value is margin
# this may make builtin evaluation metric not function properly
# for example, we are doing logistic loss, the prediction is score before logistic transformation
# the builtin evaluation error assumes input is after logistic transformation
# Take this in mind when you use the customization, and maybe you need write customized evaluation function
</span>
<span class="k">def</span> <span class="nf">evalerror</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">dtrain</span><span class="p">):</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">dtrain</span><span class="p">.</span><span class="n">get_label</span><span class="p">()</span>
    <span class="c1"># return a pair metric_name, result
</span>    <span class="c1"># since preds are margin(before logistic transformation, cutoff at 0)
</span>    <span class="k">return</span> <span class="s">'error'</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">labels</span> <span class="o">!=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">)))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

<span class="c1"># training with customized objective, we can also do step by step training
# simply look at xgboost.py's implementation of train
</span><span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">dtrain</span><span class="p">,</span> <span class="n">num_boost_round</span><span class="p">,</span> <span class="n">watchlist</span><span class="p">,</span> <span class="n">logregobj</span><span class="p">,</span> <span class="n">evalerror</span><span class="p">)</span>
<span class="n">bst</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dtest</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>start running example to used customized objective function
[0]	eval-error:0.007449	train-error:0.006756
[1]	eval-error:0	train-error:0.001228
[2]	eval-error:0	train-error:0
[3]	eval-error:0	train-error:0





array([-4.17207384,  4.17381191, -4.17207384, ...,  4.34276581,
       -3.77458525,  4.34276581], dtype=float32)
</code></pre></div></div>

<h2 id="模型持久化模型载入载出">模型持久化(模型载入载出)</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bst</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="s">'0001.model'</span><span class="p">)</span>

<span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">Booster</span><span class="p">({</span><span class="s">'nthread'</span><span class="p">:</span> <span class="mi">4</span><span class="p">})</span>  <span class="c1"># init model
</span><span class="n">bst</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">'0001.model'</span><span class="p">)</span>  <span class="c1"># load data
</span><span class="n">bst</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dtest</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([-4.17207384,  4.17381191, -4.17207384, ...,  4.34276581,
       -3.77458525,  4.34276581], dtype=float32)
</code></pre></div></div>

<p>参考：</p>

<p><a href="http://xgboost.readthedocs.io/en/latest/python/python_intro.html">XGBoost原生API漫步</a></p>

<h2 id="利用xgboost生成新特征和特征离散化">利用XGBoost生成新特征和特征离散化</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>  
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>  
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_hastie_10_2</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>  
<span class="kn">from</span> <span class="nn">xgboost.sklearn</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>  


<span class="c1">#生成二分类数据集(10个特征)
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_hastie_10_2</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train_1</span><span class="p">,</span> <span class="n">X_train_2</span><span class="p">,</span> <span class="n">y_train_1</span><span class="p">,</span> <span class="n">y_train_2</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  

</code></pre></div></div>

<h3 id="数据集划分">数据集划分</h3>

<p>训练集1+训练集2=0.9 * 全部数据集</p>

<p>训练集2 = 0.6 * （训练集1 + 训练集2）</p>

<p><img src="http://wx3.sinaimg.cn/mw690/aba7d18bgy1fknspkf4jjj20fu01ydfp.jpg" alt="数据集划分" /></p>

<h3 id="利用训练集1训练分类器">利用训练集1训练分类器</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>  
    <span class="n">learning_rate</span> <span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>  
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  
    <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  
    <span class="n">gamma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>  
    <span class="n">subsample</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span>  
    <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span>  
    <span class="n">objective</span><span class="o">=</span> <span class="s">'binary:logistic'</span><span class="p">,</span>
    <span class="n">nthread</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  
    <span class="n">reg_alpha</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span>  
    <span class="n">reg_lambda</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_1</span><span class="p">,</span> <span class="n">y_train_1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.75,
       gamma=0.5, learning_rate=0.2, max_delta_step=0, max_depth=8,
       min_child_weight=10, missing=None, n_estimators=200, nthread=8,
       objective='binary:logistic', reg_alpha=1e-05, reg_lambda=10,
       scale_pos_weight=1, seed=0, silent=True, subsample=0.75)
</code></pre></div></div>

<h3 id="特征离散化和特征合并">特征离散化和特征合并</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_feature</span><span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">X_train_2</span><span class="p">)</span>  
<span class="n">X_train_new2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_train_2</span><span class="p">,</span> <span class="n">new_feature</span><span class="p">))</span>
<span class="n">new_feature_test</span><span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>  
<span class="n">X_test_new</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_test</span><span class="p">,</span> <span class="n">new_feature_test</span><span class="p">))</span>
</code></pre></div></div>

<hr />

<p>提示：矩阵合并(ndarray)</p>

<p>1.两个矩阵的横/纵合并:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>D = np.hstack((A,B))   

D = np.vstack((A,B))
</code></pre></div></div>

<p>2.多个矩阵的横/纵合并:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>C = np.concatenate((A,B,B,A), axis=0)

C = np.concatenate((A,B,B,A), axis=1)
</code></pre></div></div>

<hr />

<h3 id="获取训练集2的auc和准确度">获取训练集2的AUC和准确度</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>  
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>  
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>  
    <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  
    <span class="n">gamma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>  
    <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>  
    <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>  
    <span class="n">objective</span><span class="o">=</span> <span class="s">'binary:logistic'</span><span class="p">,</span> 
    <span class="n">nthread</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  
    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  
    <span class="n">reg_alpha</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span>  
    <span class="n">reg_lambda</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 

<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_2</span><span class="p">,</span> <span class="n">y_train_2</span><span class="p">)</span>  
<span class="n">y_pre</span><span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>  
<span class="n">y_pro</span><span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>   

<span class="k">print</span><span class="p">(</span><span class="s">"AUC Score :"</span><span class="p">,(</span><span class="n">metrics</span><span class="p">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pro</span><span class="p">)))</span>   
<span class="k">print</span><span class="p">(</span><span class="s">"Accuracy :"</span><span class="p">,(</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pre</span><span class="p">)))</span>  
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AUC Score : 0.988763545429
Accuracy : 0.931666666667
</code></pre></div></div>

<h3 id="获取训练集2合并离散特征的auc和准确度">获取训练集2(合并离散特征)的AUC和准确度</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>  
    <span class="n">learning_rate</span> <span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>  
    <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  
    <span class="n">gamma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>  
    <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>  
    <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>  
    <span class="n">objective</span><span class="o">=</span> <span class="s">'binary:logistic'</span><span class="p">,</span>
    <span class="n">nthread</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  
    <span class="n">reg_alpha</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span>  
    <span class="n">reg_lambda</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 

<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_new2</span><span class="p">,</span> <span class="n">y_train_2</span><span class="p">)</span>  
<span class="n">y_pre</span><span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_new</span><span class="p">)</span>  
<span class="n">y_pro</span><span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_new</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>   
<span class="k">print</span><span class="p">(</span><span class="s">"AUC Score :"</span><span class="p">,(</span><span class="n">metrics</span><span class="p">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pro</span><span class="p">)))</span>   
<span class="k">print</span><span class="p">(</span><span class="s">"Accuracy :"</span><span class="p">,(</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pre</span><span class="p">)))</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AUC Score : 0.987232564601
Accuracy : 0.939166666667
</code></pre></div></div>

<hr />

<p>提示：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.合并离散特征后准确度有所提升(未调参)。

2.特征离散化的一种方式。
</code></pre></div></div>

<p>参考：</p>

<p>《Practical Lessons from Predicting Clicks on Ads at Facebook》</p>

<hr />

<h3 id="使用xgboost原生接口生成新特征">使用XGBoost原生接口生成新特征</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="n">xgb</span>
<span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="s">'data/agaricus.txt.train'</span><span class="p">)</span>
<span class="n">dtest</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="s">'data/agaricus.txt.test'</span><span class="p">)</span>

<span class="n">param</span> <span class="o">=</span> <span class="p">{</span><span class="s">'max_depth'</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span>
         <span class="s">'eta'</span><span class="p">:</span><span class="mf">0.8</span><span class="p">,</span>
         <span class="s">'objective'</span><span class="p">:</span><span class="s">'binary:logistic'</span><span class="p">}</span>

<span class="n">watchlist</span>  <span class="o">=</span> <span class="p">[(</span><span class="n">dtest</span><span class="p">,</span><span class="s">'eval'</span><span class="p">),</span> <span class="p">(</span><span class="n">dtrain</span><span class="p">,</span><span class="s">'train'</span><span class="p">)]</span>
<span class="n">num_boost_round</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">dtrain</span><span class="p">,</span> <span class="n">num_boost_round</span><span class="p">,</span><span class="n">watchlist</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="s">'start testing predict the leaf indices'</span><span class="p">)</span>
<span class="c1">### predict using first 2 tree
</span><span class="n">leafindex</span> <span class="o">=</span> <span class="n">bst</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dtest</span><span class="p">,</span> <span class="n">ntree_limit</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pred_leaf</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">leafindex</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">leafindex</span><span class="p">)</span>
<span class="c1">### predict all trees
</span><span class="n">leafindex</span> <span class="o">=</span> <span class="n">bst</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dtest</span><span class="p">,</span> <span class="n">pred_leaf</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">leafindex</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0]	eval-error:0.007449	train-error:0.006142
[1]	eval-error:0	train-error:0.000614
[2]	eval-error:0	train-error:0.000614
start testing predict the leaf indices
(1611, 2)
[[10 10]
 [13  7]
 [10 10]
 ..., 
 [13  7]
 [15 14]
 [13  7]]
(1611, 3)
</code></pre></div></div>

<hr />

<h2 id="使用xgboost获取特征重要性">使用XGBoost获取特征重要性</h2>

<p>提示:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. kernel=Python2.7, 添加代码%matplotlib inline

2. kernel=Python3.0, 不需要添加1.的代码，图片风格和1.不同且Python3.0更好
</code></pre></div></div>

<hr />

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">ax</span><span class="o">=</span><span class="n">xgb</span><span class="p">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">bst</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="http://wx3.sinaimg.cn/mw690/aba7d18bgy1fknwvh0826j20ca07t0sr.jpg" alt="png" /></p>

<hr />

<h2 id="使用xgboost绘制和存储决策树">使用XGBoost绘制和存储决策树</h2>

<p>提示:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. kernel=Python2.7环境下运行，添加代码%matplotlib inline

2. kernel=Python3.0，报错：You must install graphviz to plot tree(在MAC OS X系统下尚未解决且不打算解决)
</code></pre></div></div>

<hr />

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ax</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">bst</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="http://wx4.sinaimg.cn/mw690/aba7d18bgy1fknwvhfausj207n074aa5.jpg" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">codecs</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">codecs</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="s">'xgb_tree.png'</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'wb'</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">to_graphviz</span><span class="p">(</span><span class="n">bst</span><span class="p">)</span>
<span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="n">pipe</span><span class="p">(</span><span class="s">'png'</span><span class="p">))</span>
<span class="n">f</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

  </article>

  <!-- mathjax -->
  
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  </div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">

    <h2 class="footer-heading">ZHPMATRIX blog</h2>

    <div class="footer-col-1 column">
      <ul>
	 <li><a href="https://mp.weixin.qq.com/s?__biz=MzU2MTY2ODEzNA==&mid=2247484598&idx=1&sn=ffbf5407ffd399a591930023639b2560&chksm=fc740dffcb0384e9f8fd98446fb0279fff5d4660fa78aed349b2ae15b2192b037900f9d3943f&token=1310413677&lang=zh_CN#rd">微信公众号《KBQA沉思录》</a></li>
        <li><a href="mailto:zhpmatrix@gmail.com">Gmail邮箱</a></li> 
        <li><a href="https://weibo.com/u/2879902091">微博</a></li> 
      </ul>
    </div>

    <div class="footer-col-2 column">
      <ul>
        <li>
          <a href="https://github.com/zhpmatrix">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">zhpmatrix</span>
          </a>
        </li>
       </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">致力于算法，数据和工程的全链路打通</p>
    </div>

  </div>
  
</footer>


    </body>
</html>
