---
layout: post
title: "[论文阅读]《A Neural Compositional Paradigm for Image Captioning》"
excerpt: "NIPS2018的文章，用于解决Image Captioning问题，整体上没有采用端到端的思路，不过其中的语言生成策略或许有值得借鉴的地方。"
date: 2019-01-30 18:00:00
mathjax: true
---

近年来关注度比较高的是神经图片描述(Neural Image Captioning，简称NIC)。从模型架构上，是一个encoder-decoder框架，encoder端利用一个大的网络结构对图片进行编码，得到图片的表示向量。然后将该图片向量作为decoder端的第一个时间步的输入，从第二个时间步开始，decoder端的输入变成caption文本。

这篇文章从整体上没有采用端到端的思路，而是将caption过程分为两个阶段。

第一，从给定图片中提取显式的语义表示(encoder端的任务，非隐式)。

第二，基于一个递归组合过程，用自底向上的方式构建caption文本(decoder端的任务)。

那么，问题来了。啥是显式的语义表示？怎么做递归组合？为什么自底向上，对谁自底向上？

语义是对图片内容的理解，表示一种描述方式。显式可以用一句话具体来描述。具体而言，给定下边一张图片，

![dog](http://wx1.sinaimg.cn/square/aba7d18bly1fzoo1o19v5j207q040acr.jpg)

第一阶段可以输出，"一片草地"，"一只小狗"，"一个足球"等，这就是显式的语义表示。具体怎么来做？

多标签分类。这个多标签分类模型的输入是图片，输出是"一片草地"(a field)，"一只小狗"(a small dog)，"一个足球"(a football)等多个标签。

印象中第一次有类似想法的是师弟在分享视频问答的解决方案时，然后就是这次了。虽然从任务建模上略显怪怪的，但是是可行的。

分析上述给定的三个标签，都是名词短语。也就是强调对名词的修饰，描述了名词的数量和大小等。作者观察到MS-COCO虽然有120K的图片，但是caption文本中只有3K的名词短语。

因此，无论从语义上，还是数量上，都可以通过一个多标签分类的模型实现对图片语义的提取。(_个人非常喜欢这种解决问题的思路。通过对数据集的具体观察，使用一个旧的建模方式解决一个新的任务，而且这种建模方式是简单的。_)

这里存在几个需要考虑的细节，需要提一下。

第一，如何提取名词短语？

第二，3K的多标签分类模型设计？

第三，模型泛化性的思考。MS-COCO虽然足够大，但是3K的标签能否作为常见数据集的名词短语上的描述，也就是一个任务开闭的问题。

关于第三，在VQA中同样是一个值得思考的问题。

OK，这块可以写代码了。

第二阶段的实现需要借助两个模块，分别是连接模块(The Connecting Module)和评估模块(The Evaluation Module)。

连接模块用于连接名词短语和连接短语。名词短语就是上文中提到的名词短语，那么连接短语呢？同样从caption中提取到的连接短语是数目有限的(1K左右)。

所谓连接短语，如"正在玩儿···"(playing with)等，连接模块得到的结果可以是：

一只小狗正在玩儿一个足球。(a small dog playing with a football)

让我们看看这里做的事情。输入是两个名词短语，输出是一个连接短语。由于连接短语池固定，因此显然，这里又可以可构建一个分类模型搞定。

这里值得思考的是，如果只是使用两个名词短语作为输入，则由于名词短语较短，本身含有的语义信息较少，很难得到最终的连接短语。

因此这里不能免俗，将图片的特征也作为输入。在输入输出确定的时候，如何设计一个分类模型，并不是这里想要讨论的问题。具体可以参照论文给出的一个模型设计，主要基于LSTM和Attention机制。同时需要考虑顺序问题，包括以下两个方面：

第一，分类模型中两个名词短语的先后顺序；

第二，一张图片对应多个标签，也就是多个名词短语。对该张图片的描述需要遍历对应的多个名词短语；

这个模块同样存在需要考虑泛化的问题。因为标签的设计和名词短语一样，都是取自caption文本。

由上述分析可知，一张图片会有多种caption候选描述，那么要选择最合适的caption文本，需要评估模块的参与。既然是评估文本的合理性，这就回到NLP关心的问题了，有很多思路。这里指的一提的是，文章又是构建了一个基于LSTM的二分类模型，对caption文本的合理性进行评估。

连接模块和评估模块讲完之后，就可以描述第二阶段做的事情了。

给定一张图片，通过第一阶段的分类模型获取名词短语标签。从名词短语标签中取两个名词短语，融合图片特征，送入一个多分类器中，得到连接词短语，也就形成了caption文本。调用评估模块判断该caption文本是否有效，如果有效，结束caption过程；如果无效，将该caption文本放入名词短语标签集中作为候选名词短语。

递归组合和自底向上都在这段话中了。

不考虑技术细节，整体上三个分类器加上一些中间策略完事儿。

阿飞提过一个问题：NIC中描述的对象越多越好，还是对某个对象描述的越具体越好？个人理解，对某个对象描述具体要求比较强的语义理解能力，这里的"具体"也是一个含义丰富的概念。要知道目前大家更多的还是在讨论名词短语中的名词的问题，而非一些修饰词。描述对象的数量按照文章的思路，多标签分类模型不差，就可以做到上限为3K的描述。

作者群来自商汤-港科大联合实验室，Toronto大学向量学院，NVIDIA。按照文章的描述，这种方法要求更少的数据，更好的泛化能力，同时可以产生更加多样化的caption文本。具体的模型细节，评估结果等可以参照原始论文，从流程上讲，复现难度不高。语言是有层次性结构的，这种方法显式的去构造层次性的描述文本，直接通过图像获取属性文本，也就是语言层次的叶子节点，实现了生成的可控。但是正如文章中考虑的那样，结构空间的大小是否受限值得思考。

比起魔改模型细节单纯的端到端，我更加喜欢这种方式。由于不是专门研究NIC问题的，只是CTO推荐了这篇文章，而且和个人品味一致，按照自底向上，通过组合的思路来生成句子，并且放在NIC的任务设定下有效，因此就读一读这篇文章了。能否将该种思路用于NLP的句子生成是最需要思考的问题。



















