---
layout: post
title: "关于Blending和Stacking的讨论"
tags: [机器学习]
excerpt: "这篇博客讨论了模型融合技术中的Blending和Stacking，分析了二者之间的关系，同时开了Stacking和神经网络的脑洞。"
date: 2017-10-19 14:12:00
mathjax: true
---



看了很多的比赛方案，大家经常谈到特征工程和模型融合，模型融合部分常用的策略是**voting**和**averaging/weight**，而且不同模型的weight是根据线上成绩手动得到。其实这个weight是可以通过学习的方式得到的，这是一种非常朴素的建模。今天复盘IJCAI-2017口碑商家流量预测大赛，对融合的理论做了进一步思考，同时分析了blending和stacking之间的关系，开了stacking和神经网络的脑洞。

模型融合要求**模型之间精度相近，模型之间差异性大**。在模型融合的时候，经常面临的一种场景是队伍中单独训练了三个不同的模型，例如SVM, XGBoost, RandomForest,每个模型都会在测试集上得到一个结果，这个时候可以给每个模型的预测加一个权重，并且使得权重之和为1。

问题是如何选择权重？很多比赛选手根据线上成绩反馈手动设置，本博客讨论机器学习的方式获得权重。

下图是线性Blending的示意图。


![Linear Blending](http://wx3.sinaimg.cn/mw690/aba7d18bgy1fknjijl84nj20nv0asmxc.jpg)

假设数据集分割如下：

![Split Data](http://wx3.sinaimg.cn/mw690/aba7d18bgy1fknjyoqxtzj20e602swed.jpg)

利用训练集和验证集1分别训练三个模型A,B,C。在这种划分中，固定了训练集/验证集，当然可以采用CV进行模型选择和参数训练。使用训练好的三个模型分别预测验证集2，得到预测结果。假设验证集2的样本数目为N，预测后可以得到一个Nx3的矩阵，为了得到每个模型的预测权重，可以将该矩阵作为训练样本，验证集2的真实标签作为label/target, 采用线性回归进行参数学习。

模型是不是很简单？这样是否合理？线性回归模型得到的特征系数(模型参数)表明了该特征对结果的贡献（重要性）。得到系数之后，预测阶段的操作很显然，每个模型单独预测测试集，然后按照上一步学习到的特征系数给每个模型的预测结果进行加权，求和之后得到最终的预测结果。

假设三个模型的预测结果相同，则三个系数都为1/3，也就是三个模型预测结果的平均值。这里的平均值是在模型预测结果相同的前提假设下成立的。在模型预测结果差异性大的前提下，摘要提到的averaging，理论上效果不好，而在此前提下，线性回归能够自动调节系数，可以得到更加合理，解释性更强的结果。

很显然，Linear Blending也有缺点，那就是增加了一次训练过程，在第二层的训练过程中，如果模型相对简单，比如说使用线性回归模型，训练代价是可以接受的。但是如果使用比较复杂的模型，则会引入新的学习参数，增加新的调参负荷。但是结合实际情况，在我看来，选择LR模型应该可以了，因为通常情况下，既然做模型融合，单个模型的结果应该已经很不错了，也就是满足预测结果差异性小的前提假设，这种情况下只需要对模型预测权重进行微调。

从上述描述过程中，提到了"层"的概念。通常认为单模型训练为第一层训练过程，将第一层训练得到的模型预测结果作为训练样本，也就是输入，训练线性回归模型，称为第二层训练过程。对于Linear Blending，线性回归模型的表达式清晰且模型解释性很好。

怎么样，个人以为，Linear Blending已经可以在比赛中使用了。

下面再看一个看似比较复杂的融合方式，称为Any Blending，或者说Stacking，或者说堆栈泛化(可能此处学术概念不太准确)。

![Any Blending](http://wx1.sinaimg.cn/mw690/aba7d18bgy1fknjij3onvj20od0auta6.jpg)

上图也是一个两层训练融合方式。对模型A，假设对训练集进行4折划分，这样遍历完整个数据集(一个Epoch)，会得到四个子模型，可以记做A0, A1, A2, A3, 为啥？每个子模型的输入训练数据不同。每个子模型单独预测测试集合，最后对四个子模型的预测结果求平均得到一个列表记为PA，同时合并每个子模型对剩下一折的样本的预测结果。合并的意义是把每个预测结果放入一个列表，记为FoldPA，列表的长度和原始训练集的长度就一样了。假设训练数据样本个数为N，测试数据样本个数为M，则FoldPA的shape为(N，1)，PA的shape为(M,1)。

对模型B和C同理可以得到PB,PC,FoldPB,FoldPC。

精彩的来了，来到第二层训练。

合并FoldPA, FoldPB, FoldPC,得到训练集合。合并PA, PB, PC得到测试集合。也就是模型D的训练数据的shape为(N,3), 测试数据的shape为(M,3)。**训练好的模型D直接预测测试数据。**是不是觉得和Linear Blending类似呢？

假设对训练数据集分成2折，模型D采用线性回归模型，就是Linear Blending了。其实**Any Blending是对Linear Blending的扩展，个人认为从两个方面进行了扩展，第一是对数据集的划分上，采用多折划分，可以有效防止overfitting，另一个方面是从第二层训练模型的选择和使用上。**

在Linear Blending中，当我们采用线性回归模型的时候，获得了可解释的模型参数，也就是每个模型预测结果的贡献。但是如果模型D的选择在解释性上并不太好呢？我们或许不需要得到模型D对测试集预测结果的清晰的数学描述，直接将PA,PB,PC合并而成的测试样本喂给模型D就可以了。模型D本来就是特征和label/target的映射关系的表达，何必在意这种映射关系具体是怎样的呢？类比线性回归和多层神经网络在模型可解释性上的差异。

这种找到方法之间本质联系的感觉是不是特别棒？嗯，让我们继续开开脑洞，不保证下述所谈内容的正确性，需要实验结果支撑。

这个东西是不是和多层神经网络类似呢？从第一层来看，可以通过加模型来扩展神经网络层的宽度。深度的扩展当然是加层，上文中谈到的Any Blending才仅仅2层，可能的一种扩展为3层的方式如下。第一层用四个模型，第二层训练的时候分别训练两个模型，其中第一个模型使用第一层的前两个模型的预测结果，第二个模型使用后两个模型的预测结果。对第二层的训练数据进行多折划分，可以在第三层训练一个模型。其实当想到对第二层的训练数据进行划分的时候，这个多层训练的结构已经可以扩展下去了。和神经网络模型相比，该模型需要每次得到前一层的结果才可以进行下去，而神经网络模型利用BP算法更新参数。由于ensemble多个模型，每个模型的复杂度都很高，这种方式有利于local方式分模块调参，而神经网络模型其实是一个广义递归线性模型，适合global方式的参数更新。

......嗯，还有很多，停止YY。



