---
layout: post
title: "[Linux]Linux下的文本处理工具"
excerpt: "在很多数据处理场景下，很多人倾向于屠龙刀和倚天剑，如果一不小心砍歪了，重新抡起刀剑砍就是了。但是如果砍一下的cost很大的情况下，不如用匕首补刀。而Linux下的文本处理工具就像这把匕首，更贴切的感觉像是一把瑞士军刀，小而功能齐全。"
date: 2017-11-14 18:43:00
mathjax: true
---

前言: 这篇Blog结合自己日常的需求，这些需求基本分布在长尾，梳理Linux下的文本处理三件利器。当然可能包含一些其他的工具。因为是结合自己的需求，所以不求全，只求实用有用。

### grep

"在我公开grep这个命令之前的很长一段时间里它都是我的私有命令。"，Ken Thompson曾说道。时至今日，grep差不多已经有40年历史。

1.最常用的应用场景是kill掉某个进程，当需要查找某个进程的进程ID的时候，可以利用grep先去查找进程名字，然后得到进程ID。

    ps -aux | grep python

2.对数据进行查看，比如查找索引号为342的记录。

grep处理的数据来源是文件或者标准输入，默认对行处理。例如为了完成上述需求，命令如下：

    grep -n 342 filename

上述命令中，-n表示输出记录所在行号，filename是文件。

    cat filename | grep -n 342

上述命令是实现从标准输入中读入。除了-n参数外，还有相对有用的参数，如下：

-i: 匹配时忽略大小写

-c: 统计匹配的行数

grep强大的过滤能力来自于各种选项参数以及正则表达式的配合(此处为自己写正则表达式的能力默哀三分钟)。

### awk

awk的名字来源于三位创始人Alfred Aho,Peter Weinberger和Brian Kernighan的姓氏首字母，其实是一种解释性的编程语言。标准格式如下：

    awk [options] 'pattern {action}' filename

awk同时支持文件读入和标准输入。工程流程是按行读取输入，对于符合模式pattern的行，执行action。当pattern省略时表示匹配任何字符串；当action省略时表示执行'{print}'；它们不可以同时省略。

看下述简单的一条命令：

    cat data.txt | awk '{print $0}'

上述命令从标准输入读入，省略了pattern，执行的action是打印当前行。$0表示当前记录，$1表示第1列,$NF表示最后一列。下述命令是指定分割符的形式，在处理csv格式的文件的时候可以使用：

    cat data.csv | awk -F, '{print $0}'

其中参数F表示指定分隔符为','。

### sed

sed的英文全称是Stream Editor，竟然是一个编辑器。初始sed是下述命令：

    sed 's/^/0 &/g' old.csv > new.csv

在蚂蚁金服的比赛中，发现数据预处理阶段输出的中间数据在每行的开头少了初始化的值，假设为0。那么这个需求是给一个文件添加一列且列值为0。由于中间数据处理耗时巨大，不可能重新生成，因此使用上述命令很方便的实现需求。

其中s是替换命令，g是全局查找，&是^匹配的部分，^匹配的部分也就是所有行，因此(0 &)表示(0 匹配行)，这样就将每行的开始添加了一个默认值0。

由上述命令看到，sed接受文件读入。此外，sed也可以处理标准输入。如果有多个文件需要处理，结合shell脚本写逻辑效果更棒。

总结：Linux下的文本处理工具很多，包括但不限于find，grep，sort，cut，awk，sed ，uniq， tee，tr，diff，cmp，split(将大文件分割成小文件)，xargs(xargs命令是给其他命令传递参数的一个过滤器，也是组合多个命令的一个工具)。在数据处理中，如果需要对数据修修补补，首先考虑这些工具能否用上有的时候能够事半功倍。

参考:

1.[如何对一个大文本进行按每行去重操作?](https://www.zhihu.com/question/28771744)

2.[基于sed的文件内容添加和删除](http://andyzhao.blog.51cto.com/794987/569613)











