---
layout: post
title: "你的样本OOD啦"
tags: [NLP]
excerpt: "Out of Distribution是又一个工业界非常实际的问题。多数情况下，我们假定IID成立，但是实际当模型面向用户时，用户会带来OOD的样本。你不能说，OOD啦，不是我的锅吧？"
date: 2020-02-14 10:25:00
mathjax: true
---

**前言：**

原来打算自己整理的，但是在整理过程中，读到知乎的一篇文章，见相关参考中的1，能够满足给我自己科普的目的，因此暂且就不写很多。另外，个人对OOD问题的关注是从Bengio开始的，其实学术上，基本可以认为OOD=Novelty Detection=Outlier Detection，这样的话，类似的工作应该就相对比较多了。理论上，既然IID是一个很强的假设，那么就应该有对OOD的研究。实际上，围绕OOD的工作确实挺多的。此外，该方向上的工作，也可以作为AutoML的一个子分支。

因此，建议直接移步相关参考1。

1.《Can You Trust Your Model’s Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift》,NeurIPS 2019

什么时候讨论uncertainty？输入分布和训练分布不一致的时候。这里说为什么会不一致？OOD和Data Shift。怎么检测OOD(Out of Distribution)的样本本来就是一个有意思的问题，模型要具有拒识的能力。比如模型是用来做金融文本分类的，用户输入文学文本做分类。Data Shift也是一个有意思的问题，可能的一个场景是：模型的训练数据是采样自春天，但是实际测试的数据是冬天的，这里有OOD的感觉，但是实际上有明显的Shift的过程。除此之外，一些广告，搜索，推荐领域类似问题应该较多。文章举了一个简单的例子：

针对多分类问题，对OOD，输入测试样本的类别不是训练样本的类别。对Data Shift，测试样本的类别是训练样本的类别中的，但是有样本损坏或者扰动，文章并没有量化这种扰动或者损坏。 

这篇文章可以认为是一篇Review，比较了几种相对流行的校准方法。

+ 最大化softmax概率是一个baseline。

+ 用于分类任务的Temperature Scaling。实现起来相对简单，给定验证集，将softmax中的logit除上一个温度系数，学习这个温度系数。Temperature Scaling可以用在很多场景，除此之外，包括蒸馏技术，用于OOD检测的其他工作，如这篇[文章](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.02690)等。

+ Ensemble也可以归为一种代表方法，围绕Ensemble的讨论工作很多，这里不再展开。

+ Inference时打开Dropout开关。本质上也是一种Ensemble的实现方式。

+ Bayes相关的方法。

文章的结论是：Ensemble最好。但是实际上工业界在考虑落地时，由于该类方法开销较大，因此基本不考虑。

2.《A Baseline For Detecting MisClassified And Out Of Distribution Examples In Neural Networks》，ICLR2017

这篇文章做了很多基础性的工作，给出了OOD的基本假设，评测，Baseline等。文章认为：模型的概率输出不能当做模型的置信度。提出一个Baseline，用统计的方法卡阈值得到OOD。

3.《Likelihood Ratios for Out-of-Distribution Detection》，NeurIPS2019

这篇文章提出了一个数据集，并用深度生成模型的方法做OOD问题。其实，将OOD当成一个异常值检测问题也是合理，因此用生成方法做似乎也可以理解。因为个人目前的兴趣点并不在生成模型，因此略过。[Google的Blog介绍](Improving Out-of-Distribution Detection in Machine Learning Models)。

4.《From System 1 Deep Learning to System 2 Deep Learning》Yoshua Bengio，NeurIPS 2019，AAAI2020，Bengio又做了一次几乎相同的Talk

该Talk中，OOD是重点讨论的内容之一。

总结：看到一些文章说OOD在**安全问题**上很重要，的确是的，如果模型给OOD一个很高的置信度，怕会不开心吧。在相关参考2的Review中，给出了其他相关场景下的应用。

5.《Generalized ODIN: Detecting Out-of-distribution Image without Learning from Out-of-distribution Data》

这篇工作的泛化版本：《Enhancing the reliability of out-of-distribution image detection in neural networks》。
文章中提到：

> In recent years, a popular neural network-based baseline is to use the max value of class pos- terior probabilities output from a softmax classiﬁer, which can in some cases be a good indicator for distinguishing in-distribution and out-of-distribution inputs.

正是上文中2提到的工作。




相关参考：

1.[知乎的文章](https://zhuanlan.zhihu.com/p/102870562)，这篇文章主要讨论了OOD的基本概念，解决OOD的四种经典的路子，相关的代表性文章及其部分细节。

2.《A Review of Novelty Detection》，2014年

3.[github-awesome系列](https://github.com/ashafaei/out-of-distribution-detection)