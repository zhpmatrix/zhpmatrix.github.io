---
layout: post
title: "[NLP]snorkel相关论文阅读"
excerpt: "snorkel是一个框架，通过该框架可以用弱监督的方式产生数据，减少人工标注的数据缺失的问题，尤其适合于信息抽取任务。"
date: 2019-06-05 18:43:00
mathjax: true
---

为了得到一个实体识别和关系抽取的模型，这里假设通过一个模型可以完成两件事情。我们需要有标注的数据，为了得到数据，可以有两种方式：

（1）人工打标签。缺点是成本巨大，优点是噪音较少。_一个具体的例子：腾讯的一个文档级关系抽取的工作，打标签5000篇文章，在标注工具辅助下，花了大概十多万。_

（2）弱监督数据。利用如distant supervision的方式等。缺点是噪音较大，优点是成本较小。

在理想情况下，我们希望通过（1）拿到数据。但是实际情况下，需要从（2）着手拿到数据。因此，[snorkel](https://github.com/HazyResearch/snorkel)主要是为(2)服务的一个框架。

**重点提示：虽然有噪音，但是不影响我们借助于snorkel可以得到一个效果很不错的模型，相关论文中多次提到snorkel在多个机构和场景下的应用取得的不错的效果！**

**重点提示：目前snorkel在关系抽取上的应用也是只关注关系抽取，实体识别的模型应该还是要单独来做。因为snorkel在数据端需要先得到候选实体。**

如果想对snorkel建立一个直观印象，1和6是不错的论文，之后可以读7，完了之后过snorkel的tutorial，其余论文可以后期跟进。


**1.《Snorkel: Fast Training Set Generation for Information Extraction》**

这是要读的第一篇论文，短短四页，用一个具体的关系抽取的例子解释了snorkel的多个概念等，通俗易懂，可以帮助建立对snorkel的直观印象。


整体上看，snorkel将劳动力从标注数据和特征工程的泥淖中解放出来，投放到写标签函数的任务中。snorkel可以让用户通过写标签函数的方式产生大量的带有噪音的训练数据。注意，得到的数据有两个特点：第一是量大，第二是有噪音。这里的核心概念是**标签函数**。标签函数的输入是候选三元组(关系抽取的背景知识不再介绍)，输出是关系是否成立？标签函数的实现分为三大类，如下：

（1）启发式

（2）规则

（3）弱监督的方式。具体包括：distant supervision，crowdsourcing，ensembling of less accurate classifiers

一般而言，在snorkel框架下，用户会定义很多的标签函数。那么这些标签函数会表现出三种行为：

（1）较低的准确率。比如，单一靠写规则的方式判断一个关系是否成立还是有些不靠谱的。

（2）冲突。在一个标签函数中判断成立的关系，在另外一个标签函数中判断就不成立了。

（3）重叠。一个关系在多个标签函数中被判断成立。

既然用户自定义标签函数，那么需要对标签函数的质量进行评估。评估的内容主要也是包含上述三个方面，除此之外，标签函数的输出是估计标签，因此对估计标签的分布的评估也是需要的。但是，不要担心，snorkel会自动地根据标签函数的行为，得到最终的关系标签。具体是通过**学习**的方式。

snorkel是什么已经有了大致的印象了。那么这里简单谈一谈snorkel的设计哲学。**snorkel的设计基于data programming paradigm，并且认为我们可以将训练数据的标注建模为一个随机过程。**

那么什么是data programming paradigm？这里暂时不做过多展开，感兴趣可以阅读相关论文。简单来说，该paradigm可以划分为两个阶段：

（1）用一个生成模型建模标签函数的输出，得到估计的标签。

（2）用估计的标签训练最终的模型。

在此设计哲学下，snorkel的系统设计分为三个部分：

（1）预处理

该阶段可以自动地把输入数据表示为一个**非结构化上下文**的**层级**结构。例如，一篇文章可以被分割为标题和内容部分，内容部分又可以被分割为段落和句子。

（2）写标签函数

标签函数是简单的python函数，把候选三元组作为input，输出是True,False或者None。

（3）自动化建模和训练

有了大量，带有噪音的数据，自然就可以训练下游模型了。

2.**《Data Programming: Creating Large Training Sets, Quickly》,NIPS2016**

这篇文章和上篇文章的作者基本相同，上篇偏重于实践，这篇偏重于理论。文章共27页，正文8页，其余都是理论证明。文章总体上阐述了data programming的motivation，概念和关键技术点：如何对标签函数之间的依赖进行建模。在最后的实验部分，通过三个实验证明三个结论：

（1）在真实世界的三个关系抽取任务上，证明了data programming是有效的paradigm；

（2）该paradigm可以和下游自动特征生成方法(或者说下游模型，如LSTM)一块工作；

（3）该paradigm对domain-expert用户非常友好（有助于写标签函数）；

3.**《Learning the Structure of Generative Models without Labeled Data》，ICML2017**

延续上篇工作的主要内容。生成模型的依赖结构直接影响估计标签的质量，但是在没有标注数据的前提下自动选择一个结构是有挑战性的。这篇文章提出一个结构估计方法，通过**最大化可观测数据的L1正则化边缘伪似然**来自动选择一个好的结构。

相关工作还有这篇，《Inferring Generative Model Structure with Static Analysis》，都是围绕依赖结构的选择问题。

4.**《Training Complex Models with Multi-Task Weak Supervision》，AAAI2019**

浏览了摘要部分，扩展了弱监督学习的setting，提出多任务弱监督的setting。实验部分在三个细粒度分类问题（实体分类，关系分类和文档分类）上，取得了很不错的结果（都是和有监督的方法来比较）。

相关工作还有这篇，《The Role of Massively Multi-Task and Weak Supervision in Software 2.0》。

5.**《Learning to Compose Domain-Specific Transformations for Data Augmentation》**

在数据增强上的一个应用，有意思。

6.**《Snorkel Fast Training Set Generation with Weak Supervision》**

主要内容和1相似，不过内容更加丰富。这篇论文中的系统overview做的很不错。

7.**《Data Programming with DDLite_Putting Humans in a Different Part of the Loop》**

DDLite可以认为是snorkel的前身。这篇文章主要讨论了标签函数的开发流程，文章中的迭代流程图做的很不错。同时给出了进一步的三个工作，有意PR的同学可以关注：

（1）userful metics

（2）data exploration and rule suggestion

（3）principled management of labeled data

8.**《Fonduer: Knowledge Base Construction from Richly Formatted Data》**

在知识图谱补全方面的一个工作，从富文本中提取知识。文章中提出了一个多模态的LSTM用于候选实体，特征设计上有意思。从我们目前自己的工作来看，知识图谱的构建正处于第一个阶段：直接从网页上提取带有结构标签的数据；可能稍后的工作包括：从非结构化文本中提取；从富文本中提出；知识图谱的去噪等展开。














